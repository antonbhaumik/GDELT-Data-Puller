"""
Here, we do some data analysis with the data generated by gdelt.py, to reduce the number of articles to read.
"""

# Inbuilt (standard library) modules
import os
import shutil

# Modules to install (see requirements.txt)
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


def group_dates(dates):
    """
    This function groups dates such that no two consecutive dates are >2 days apart.
    :param dates: The dates to group.
    :return: The groups.
    """
    date_groups = []
    current_group = 0
    for i in range(len(dates)):
        if i == 0:
            date_groups.append(current_group)
        else:
            if (dates.index[i] - dates.index[i - 1]).days > 5:
                current_group += 1
            date_groups.append(current_group)
    return date_groups


def analyse_data(file, volume):
    # Output file name definitions
    if volume:
        name = 'volume'
    else:
        name = 'tone'

    # Read the data and clean it
    df = pd.read_csv(f'{folder}/{file}.csv', on_bad_lines='skip')
    df = df[df['Series'] != 'Total Monitored Articles']
    df['Date'] = pd.to_datetime(df['Date']).dt.date
    df.set_index('Date', inplace=True)

    # Now, we smooth with a 14-day moving average, then get values val>3*std+mean as outliers. Next, we group the
    # articles by dates close to each other, then take only the articles of the date in the group with the most
    # published articles.
    df['Moving Average'] = df['Value'].rolling(window=14, center=True).mean()
    if volume:
        df['Differences'] = df['Value'] - df['Moving Average']
    else:
        df['Differences'] = np.abs(df['Value'] - df['Moving Average'])
    mean_diff = df['Differences'].mean()
    std_diff = df['Differences'].std()
    outliers = df[df['Differences'] > mean_diff + 3 * std_diff]
    outliers['Group'] = group_dates(outliers)
    outliers = outliers.loc[outliers.groupby('Group')['Value'].idxmax()]

    # Plot the data and save it
    df['Value'].plot()
    plt.scatter(outliers.index, outliers['Value'], color='red', label='Outliers')
    if volume:
        plt.title('News Article Volume')
    else:
        plt.title('Article Tone')
    plt.xlabel('Date')
    plt.ylabel('Article Count')
    plt.grid(True)
    plt.savefig(f'analysis/{name}.png', dpi=300, bbox_inches='tight')
    plt.legend()
    plt.show()

    # Now, get the relevant headlines for the outliers - we get the translated dataframe if available, else the original
    if os.path.exists('output/ArtListTranslatedNoDuplicates'):
        df = pd.read_csv(f'{folder}/ArtListTranslatedNoDuplicates.csv', on_bad_lines='skip')
    else:
        df = pd.read_csv(f'{folder}/ArtListNoDuplicates.csv', on_bad_lines='skip')
    df['Date'] = pd.to_datetime(df['Date']).dt.date
    df = df[df['Date'].isin(outliers.index)]
    df['Group'] = outliers.loc[df['Date'], 'Group'].values
    df.to_csv(f'analysis/{name}_outliers.csv', index=False)


# Load the data from the folder - gdelt.py puts it in output/ so make that default. We also ask what to analyse.
folder = 'output/' if os.path.exists('output/') else ''
if inp := input(f'Enter the folder name for the data files{', or leave blank to use output/' if folder else ''}.\n> '):
    folder = inp
if not folder:
    print('Invalid folder provided. Exiting...')
    exit()

# Here, we empty the analysis/ folder if it already exists, creates it if it doesn't
if os.path.exists('analysis/'):
    shutil.rmtree('analysis/')
os.makedirs('analysis/')

# Call the function on the two files
analyse_data('TimelineVolRaw', True)
analyse_data('TimelineTone', False)
